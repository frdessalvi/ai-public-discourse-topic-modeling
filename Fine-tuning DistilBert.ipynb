{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b78a72",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Fine-tuning DistilBert</b></font>  \n",
    "The goal of this notebook is to fine-tune a classifier for sentiment analysis, using a baseline of manually annotated tweets. The tweets were selected to include all original labels (positive, negative, neutral). These were then annotated by us after deciding and explicitly stating the question we wanted to keep in mind while annotating. The pre-trained model used is DistilBert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b4eeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b913858",
   "metadata": {},
   "source": [
    "To facilitate the annotation process, the tweets were left unedited with all hashtags and URLs. Thus, in this first part of the notebook, the annotated tweets are processed to create the final dataset used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5f3894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial                                             Tweets Annotation\n",
      "0   13202  Now you have zero reasons to not type annotate...   Positive\n",
      "1   12423                                #glycotime #chatGPT    Neutral\n",
      "2    6686  Organizations need to embed ethics-oriented th...    Neutral\n",
      "3    2568  Study the antifragility of gamers. Crypto pric...   Negative\n",
      "4    6554  Startup Spotlight: AI Edition Today, I want to...   Positive\n",
      "Annotation\n",
      "Neutral     859\n",
      "Negative    587\n",
      "Positive    553\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the annotated dataset and convert it into the right format\n",
    "annotation_df_1=pd.read_csv('Annotation set 1.csv')\n",
    "annotation_df_2=pd.read_csv('Annotation set 2.csv')\n",
    "annotation_df_1.columns = annotation_df_1.columns.str.strip()\n",
    "annotation_df_2.columns = annotation_df_2.columns.str.strip()\n",
    "annotation_df = pd.concat([annotation_df_1, annotation_df_2])\n",
    "\n",
    "print(annotation_df.head())\n",
    "print(annotation_df['Annotation'].value_counts())\n",
    "clean_df=pd.read_csv('Cleaned data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87ce6fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Serial                                             Tweets Annotation\n",
      "0          5  theres still lots to unpack with ai (llms) the...   Positive\n",
      "1          5  theres still lots to unpack with ai (llms) the...   Positive\n",
      "2         36  ai adoption accelerated during the pandemic, b...    Neutral\n",
      "3         36  ai adoption accelerated during the pandemic, b...   Positive\n",
      "4         47  absolutely, mastering critical thinking is key...   Positive\n",
      "...      ...                                                ...        ...\n",
      "1964   25062  is this the level you're sinking to? using 4ch...    Neutral\n",
      "1965   25091  frequently the use of a word or two will trigg...    Neutral\n",
      "1966   25107  reports of israel using ai for targeting in th...   Negative\n",
      "1967   25120  using ai for israel killing machine. that is t...   Negative\n",
      "1968   25143  mfs really out here using ai for a console war...   Negative\n",
      "\n",
      "[1969 rows x 3 columns]>\n",
      "Serial        0\n",
      "Tweets        0\n",
      "Annotation    1\n",
      "dtype: int64\n",
      "label\n",
      "1    843\n",
      "0    586\n",
      "2    539\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    539\n",
      "1    539\n",
      "2    539\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df=pd.merge(clean_df,annotation_df[['Serial','Annotation']],on='Serial',how='inner')\n",
    "print(merged_df.head)\n",
    "print(merged_df.isnull().sum())\n",
    "merged_df=merged_df.dropna()\n",
    "\n",
    "# Replace string with numeric value as expected by the classifier \n",
    "label_map={'Positive': 2,'Neutral': 1,'Negative': 0}\n",
    "merged_df['Annotation']=merged_df['Annotation'].map(label_map)\n",
    "\n",
    "training_df=merged_df[['Tweets','Annotation']].copy()\n",
    "training_df=training_df.rename(columns={'Tweets':'text','Annotation':'label'})\n",
    "\n",
    "print(training_df['label'].value_counts())\n",
    "\n",
    "# Balance the classes by downsampling\n",
    "min_count = training_df['label'].value_counts().min()\n",
    "\n",
    "balanced_df = (\n",
    "    training_df.groupby('label')\n",
    "    .sample(n=min_count, random_state=42) \n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "# Save dataset for training\n",
    "balanced_df.to_csv('Training data.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902ddd0",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of the fine-tuned model, it is necessary to establish a suitable <b>baseline</b>.   \n",
    "\n",
    "A robust yet elementary baseline is implemented in the following cell, utilising TF-IDF on character n-grams, followed by logistic regression. The model achieves a good level of accuracy, with an overall accuracy of  0.6512 and a overall f1 score of 0.6416. \n",
    "We will try to achieve an higher  macro averaged f1 score fine tuning DistilBert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3faccd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7099    0.7561    0.7323       123\n",
      "           1     0.6296    0.5100    0.5635       100\n",
      "           2     0.5982    0.6634    0.6291       101\n",
      "\n",
      "    accuracy                         0.6512       324\n",
      "   macro avg     0.6459    0.6432    0.6416       324\n",
      "weighted avg     0.6503    0.6512    0.6480       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline to confront this with\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Load your preprocessed data\n",
    "df = pd.read_csv(\"Training data.csv\")\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define pipeline \n",
    "pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(analyzer=\"char\", ngram_range=(2,6))),\n",
    "        (\"clf\", LogisticRegression(class_weight=\"balanced\", max_iter=1000))\n",
    "    ])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "251e6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,f1_score\n",
    "import torch\n",
    "import accelerate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211b3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1617 examples [00:00, 48496.52 examples/s]\n",
      "Map: 100%|██████████| 1617/1617 [00:01<00:00, 969.75 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1293\n",
      "Validation dataset size: 162\n",
      "Test dataset size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's download and fine-tune the model\n",
    "\n",
    "dataset = load_dataset('csv', data_files='Training data.csv')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset['train'].map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Split dataset in train/validation/test splits \n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "\n",
    "temp_dataset = train_test_split['test']\n",
    "val_test_split = temp_dataset.train_test_split(test_size=0.5, seed=42) # Split to create validation \n",
    "\n",
    "# Get the final train, validation, and test sets\n",
    "train_dataset = train_test_split['train']\n",
    "val_dataset = val_test_split['train']\n",
    "test_dataset = val_test_split['test']\n",
    "\n",
    "# Check the sizes of each dataset\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28dc3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained DistilBERT model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe06a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frdes\\AppData\\Local\\Temp\\ipykernel_10692\\559542167.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    no_cuda=True,\n",
    "    learning_rate=1e-5\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions).argmax(dim=1)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=[0, 1, 2])\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision_negative\": precision[0],\n",
    "        \"recall_negative\": recall[0],\n",
    "        \"f1_negative\": f1[0],\n",
    "        \"precision_neutral\": precision[1],\n",
    "        \"recall_neutral\": recall[1],\n",
    "        \"f1_neutral\": f1[1],\n",
    "        \"precision_positive\": precision[2],\n",
    "        \"recall_positive\": recall[2],\n",
    "        \"f1_positive\": f1[2],\n",
    "        \"f1_macro\": f1_macro\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize trainer with the updated datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,  # Using the train dataset\n",
    "    eval_dataset=val_dataset,     # Using the validation dataset\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982ce183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='972' max='1296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 972/1296 22:26 < 07:29, 0.72 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Recall Neutral</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.934400</td>\n",
       "      <td>0.925758</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>0.467456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.580178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.782924</td>\n",
       "      <td>0.623457</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.612594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.793994</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.658033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.337100</td>\n",
       "      <td>0.818975</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.651355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.645517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.7939937114715576, 'eval_accuracy': 0.6851851851851852, 'eval_precision_negative': 0.6428571428571429, 'eval_recall_negative': 0.8490566037735849, 'eval_f1_negative': 0.7317073170731707, 'eval_precision_neutral': 0.6428571428571429, 'eval_recall_neutral': 0.391304347826087, 'eval_f1_neutral': 0.4864864864864865, 'eval_precision_positive': 0.75, 'eval_recall_positive': 0.7619047619047619, 'eval_f1_positive': 0.7559055118110236, 'eval_f1_macro': 0.6580331051235603, 'eval_runtime': 8.1643, 'eval_samples_per_second': 19.842, 'eval_steps_per_second': 2.572, 'epoch': 6.0}\n",
      "Test results: {'eval_loss': 0.807064414024353, 'eval_accuracy': 0.654320987654321, 'eval_precision_negative': 0.6176470588235294, 'eval_recall_negative': 0.7924528301886793, 'eval_f1_negative': 0.6942148760330579, 'eval_precision_neutral': 0.6923076923076923, 'eval_recall_neutral': 0.32142857142857145, 'eval_f1_neutral': 0.43902439024390244, 'eval_precision_positive': 0.6764705882352942, 'eval_recall_positive': 0.8679245283018868, 'eval_f1_positive': 0.7603305785123967, 'eval_f1_macro': 0.631189948263119, 'eval_runtime': 8.2421, 'eval_samples_per_second': 19.655, 'eval_steps_per_second': 2.548, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./sentiment_model_with_validation\\\\tokenizer_config.json',\n",
       " './sentiment_model_with_validation\\\\special_tokens_map.json',\n",
       " './sentiment_model_with_validation\\\\vocab.txt',\n",
       " './sentiment_model_with_validation\\\\added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = trainer.evaluate()\n",
    "print(\"Evaluation results:\", eval_result)\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(\"Test results:\", test_results)\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./sentiment_model_with_validation\")\n",
    "tokenizer.save_pretrained(\"./sentiment_model_with_validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451368cc",
   "metadata": {},
   "source": [
    "The final model has a macro f1 score of  approximately 0.632. Unfortunately after different attempts we couldn't manage to further improve performance, so we settled on this model which performs worst than the baseline on the macro f1 score metric. In this last snippet of code the previously cleaned data is prepared to be labeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "209b9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df=pd.read_csv('Cleaned data.csv')\n",
    "\n",
    "mask=~tweet_df['Serial'].isin(merged_df['Serial'])\n",
    "final_tweets=tweet_df[mask]\n",
    "final_tweets['Tweets'].to_csv('Tweets to label.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
